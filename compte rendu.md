# ZINEB EL MEJDOUBI
**Num√©ro d'√©tudiant** : 24010156
**Classe** : CAC2


# Compte rendu

üìä Analyse de l'√âquilibre entre Usage des R√©seaux Sociaux et Sant√© Mentale 

**Date :** 29 Novembre 2025



## Introduction
Ce projet vise √† analyser les facteurs influen√ßant l'indice de bonheur √† partir d'un jeu de donn√©es relatif √† la sant√© mentale et l'√©quilibre des m√©dias sociaux. L'objectif est de construire et d'√©valuer plusieurs mod√®les de r√©gression pour pr√©dire cet indice, ainsi qu'un mod√®le de classification pour cat√©goriser le niveau de bonheur. L'analyse mettra en lumi√®re les variables cl√©s ayant un impact significatif sur le bien-√™tre.

## Exploration et Pr√©paration des Donn√©es
Le jeu de donn√©es initial contient 500 entr√©es et 10 colonnes. Aucune valeur manquante n'a √©t√© d√©tect√©e, ce qui a simplifi√© la phase de pr√©traitement. La colonne `User_ID`, √©tant un identifiant unique, a √©t√© supprim√©e. Les variables cat√©gorielles comme `Gender` et `Social_Media_Platform` ont √©t√© transform√©es en variables num√©riques √† l'aide de l'encodage One-Hot, pr√©parant ainsi le jeu de donn√©es pour l'entra√Ænement des mod√®les.

## Analyse de Corr√©lation
L'analyse de corr√©lation a r√©v√©l√© des relations importantes entre les variables et l'indice de bonheur :
- **Stress_Level(1-10)** : Forte corr√©lation n√©gative (-0.74). Plus le niveau de stress est √©lev√©, plus l'indice de bonheur tend √† √™tre bas.
- **Daily_Screen_Time(hrs)** : Forte corr√©lation n√©gative (-0.71). Un temps d'√©cran quotidien plus √©lev√© est associ√© √† un indice de bonheur plus faible.
- **Sleep_Quality(1-10)** : Forte corr√©lation positive (0.68). Une meilleure qualit√© de sommeil est li√©e √† un indice de bonheur plus √©lev√©.

Ces corr√©lations sugg√®rent que la sant√© mentale et les habitudes de vie jouent un r√¥le pr√©pond√©rant dans l'indice de bonheur.

## Mod√®les de R√©gression
Nous avons entra√Æn√© et √©valu√© plusieurs mod√®les de r√©gression pour pr√©dire l'indice de bonheur. Voici un aper√ßu de chaque mod√®le et de ses performances.

### 1. R√©gression Lin√©aire Simple
- **Mise en ≈ìuvre** : Utilisant uniquement `Stress_Level(1-10)` comme pr√©dicteur.
- **Performance** : R-carr√© = {r2_simple:.2f}, MSE = {mse_simple:.2f}, MAE = {mae_simple:.2f}.
- **Forces** : Tr√®s simple et facile √† interpr√©ter. Bonne base pour comprendre l'impact d'une seule variable.
- **Faiblesses** : Limit√© aux relations lin√©aires, ne capture pas la complexit√© des donn√©es.

### 2. R√©gression Lin√©aire Multiple
- **Mise en ≈ìuvre** : Inclut toutes les caract√©ristiques pr√©dictives.
- **Performance** : R-carr√© = {r2_multiple:.2f}, MSE = {mse_multiple:.2f}, MAE = {mae_multiple:.2f}.
- **Forces** : Interpr√©table, prend en compte plusieurs facteurs simultan√©ment.
- **Faiblesses** : Suppose une relation lin√©aire, sensible √† la multicolin√©arit√©.

### 3. R√©gression Polynomiale
- **Mise en ≈ìuvre** : Utilise des caract√©ristiques polynomiales de degr√© 2.
- **Performance** : R-carr√© = {r2_poly:.2f}, MSE = {mse_poly:.2f}, MAE = {mae_poly:.2f}.
- **Forces** : Peut capturer des relations non lin√©aires.
- **Faiblesses** : Augmente la complexit√© du mod√®le et le risque de surapprentissage. Moins performant que la r√©gression lin√©aire multiple dans ce cas.

### 4. R√©gression Ridge (L2)
- **Mise en ≈ìuvre** : R√©gression lin√©aire avec p√©nalit√© L2 pour la r√©gularisation (`alpha=1.0`).
- **Performance** : R-carr√© = {r2_ridge:.2f}, MSE = {mse_ridge:.2f}, MAE = {mae_ridge:.2f}.
- **Forces** : Aide √† pr√©venir le surapprentissage et g√®re la multicolin√©arit√© en r√©duisant les coefficients.
- **Faiblesses** : Ne r√©alise pas de s√©lection de caract√©ristiques (les coefficients ne sont pas r√©duits √† z√©ro).

### 5. R√©gression Lasso (L1)
- **Mise en ≈ìuvre** : R√©gression lin√©aire avec p√©nalit√© L1 pour la r√©gularisation (`alpha=0.1`).
- **Performance** : R-carr√© = {r2_lasso:.2f}, MSE = {mse_lasso:.2f}, MAE = {mae_lasso:.2f}.
- **Forces** : R√©alise la s√©lection de caract√©ristiques en r√©duisant certains coefficients √† z√©ro, simplifiant le mod√®le.
- **Faiblesses** : Son efficacit√© d√©pend fortement du choix de `alpha`.

### 6. Arbre de D√©cision
- **Mise en ≈ìuvre** : Mod√®le bas√© sur un seul arbre de d√©cision.
- **Performance** : R-carr√© = {r2_dt:.2f}, MSE = {mse_dt:.2f}, MAE = {mae_dt:.2f}.
- **Forces** : Facile √† comprendre et √† visualiser (pour des arbres simples).
- **Faiblesses** : Tr√®s sensible au surapprentissage, souvent moins performant que les m√©thodes d'ensemble.

### 7. For√™t Al√©atoire
- **Mise en ≈ìuvre** : Ensemble de plusieurs arbres de d√©cision.
- **Performance** : R-carr√© = {r2_rf:.2f}, MSE = {mse_rf:.2f}, MAE = {mae_rf:.2f}.
- **Forces** : Tr√®s robuste, g√®re les relations non lin√©aires et les interactions, r√©duit le surapprentissage.
- **Faiblesses** : Moins interpr√©table que les mod√®les lin√©aires, peut √™tre co√ªteux en calcul.

## Tableau R√©capitulatif des Performances des Mod√®les de R√©gression
```
{performance_df.round(2).to_string()}
```

## Analyse de R√©gression Logistique (Classification)
Pour explorer les cat√©gories de bonheur, la variable cible `Happiness_Index(1-10)` a √©t√© discr√©tis√©e en trois cat√©gories : 'faible' (0-6), 'moyen' (7-8) et '√©lev√©' (9-10). Un mod√®le de r√©gression logistique multiclasse a √©t√© entra√Æn√©.

### Performance du Mod√®le de R√©gression Logistique
- **Pr√©cision (Accuracy)** : {model_lr.score(X_test_clf, y_test_clf):.2f}
- **Rapport de Classification** :
```
{classification_report(y_test_clf, y_pred_clf, target_names=['faible', 'moyen', '√©lev√©'])}
```
- **Matrice de Confusion** :
```
{conf_matrix}
```

### Interpr√©tation des R√©sultats de Classification
Le mod√®le de r√©gression logistique a une pr√©cision globale de {model_lr.score(X_test_clf, y_test_clf):.2f}. Il excelle dans la pr√©diction de la cat√©gorie '√©lev√©' (Rappel de {classification_report(y_test_clf, y_pred_clf, output_dict=True)['√©lev√©']['recall']:.2f}) mais peine avec la cat√©gorie 'faible' (Rappel de {classification_report(y_test_clf, y_pred_clf, output_dict=True)['faible']['recall']:.2f}), la confondant souvent avec la cat√©gorie 'moyen'. Cela est probablement d√ª au d√©s√©quilibre des classes et √† la complexit√© de distinguer les cat√©gories adjacentes. Des techniques de r√©√©quilibrage de classes pourraient am√©liorer la performance sur la cat√©gorie 'faible'.

## D√©couvertes Cl√©s
- Le **Stress_Level**, la **Sleep_Quality** et le **Daily_Screen_Time** sont les facteurs les plus influents sur l'indice de bonheur.
- Le **mod√®le de For√™t Al√©atoire** est le plus performant pour pr√©dire l'indice de bonheur, indiquant des relations complexes et non lin√©aires entre les variables.
- La r√©gression lin√©aire multiple et les mod√®les r√©gularis√©s (Ridge, Lasso) offrent des performances solides, soulignant l'importance de plusieurs caract√©ristiques simultan√©ment.
- Le mod√®le d'Arbre de D√©cision seul est moins efficace que les mod√®les d'ensemble, sugg√©rant que l'agr√©gation d'arbres est b√©n√©fique.
- La r√©gression logistique permet de classer les niveaux de bonheur, mais la pr√©diction des cat√©gories minoritaires ('faible') reste un d√©fi.

## Conclusions G√©n√©rales
Cette analyse a d√©montr√© l'importance des facteurs li√©s au mode de vie et √† la sant√© mentale dans la d√©termination de l'indice de bonheur. La capacit√© de la For√™t Al√©atoire √† g√©rer la complexit√© des relations en fait le mod√®le le plus adapt√© pour cette t√¢che. Les interventions visant √† am√©liorer le bonheur devraient cibler la gestion du stress, l'am√©lioration du sommeil et la mod√©ration du temps d'√©cran.

## Prochaines √âtapes
- **Optimisation des hyperparam√®tres** : Utiliser des techniques comme la recherche par grille (Grid Search) ou la recherche al√©atoire (Random Search) pour affiner les mod√®les, en particulier la For√™t Al√©atoire et l'Arbre de D√©cision.
- **R√©√©quilibrage des classes** : Appliquer des m√©thodes de r√©√©quilibrage (SMOTE, sur/sous-√©chantillonnage) pour am√©liorer la performance du mod√®le de r√©gression logistique sur les classes minoritaires.
- **Exploration d'autres mod√®les** : Tester d'autres algorithmes d'apprentissage automatique comme XGBoost ou LightGBM pour la r√©gression et la classification.
- **Analyse d'interactions** : √âtudier plus en profondeur les interactions entre les caract√©ristiques pour affiner la compr√©hension des relations non lin√©aires.
- **Collecte de donn√©es suppl√©mentaires** : Un jeu de donn√©es plus vaste ou incluant d'autres variables pourrait renforcer la robustesse et la g√©n√©ralisabilit√© des mod√®les.
"""

print(readme_content)
